diff --git a/site-packages/torch/__init__.py b/site-packages/torch/__init__.py
index fae804c8160..3d5616cf35a 100644
--- a/site-packages/torch/__init__.py
+++ b/site-packages/torch/__init__.py
@@ -289,7 +289,7 @@ def _get_cuda_dep_paths(path: str, lib_folder: str, lib_name: str) -> list[str]:
     return nvidia_lib_paths + lib_paths
 
 
-def _preload_cuda_deps(lib_folder: str, lib_name: str) -> None:
+def _preload_cuda_dep(lib_folder: str, lib_name: str) -> None:
     """Preloads cuda deps if they could not be found otherwise."""
     # Should only be called on Linux if default path resolution have failed
     assert platform.system() == "Linux", "Should only be called on Linux"
@@ -305,6 +305,44 @@ def _preload_cuda_deps(lib_folder: str, lib_name: str) -> None:
     ctypes.CDLL(lib_path)
 
 
+def _preload_cuda_deps(err: _Union[ImportError, OSError]) -> builtins.bool:
+    """Preloads cuda deps if they could not be found otherwise."""
+    # Can only happen for wheel with cuda libs as PYPI deps
+    # As PyTorch is not purelib, but nvidia-*-cu12 is
+    from torch.version import cuda as cuda_version
+
+    cuda_libs: dict[str, str] = {
+        "cublas": "libcublas.so.*[0-9]",
+        "cudnn": "libcudnn.so.*[0-9]",
+        "cuda_nvrtc": "libnvrtc.so.*[0-9]",
+        "cuda_runtime": "libcudart.so.*[0-9]",
+        "cuda_cupti": "libcupti.so.*[0-9]",
+        "cufft": "libcufft.so.*[0-9]",
+        "curand": "libcurand.so.*[0-9]",
+        "nvjitlink": "libnvJitLink.so.*[0-9]",
+        "cusparse": "libcusparse.so.*[0-9]",
+        "cusparselt": "libcusparseLt.so.*[0-9]",
+        "cusolver": "libcusolver.so.*[0-9]",
+        "nccl": "libnccl.so.*[0-9]",
+    }
+    # cufiile is only available on cuda 12+
+    # TODO: Remove once CUDA 11.8 binaries are deprecated
+    if cuda_version is not None:
+        t_version = cuda_version.split(".")
+        t_major = int(t_version[0])  # type: ignore[operator]
+        if t_major >= 12:
+            cuda_libs["cufile"] = "libcufile.so.*[0-9]"
+
+    is_cuda_lib_err = [
+        lib for lib in cuda_libs.values() if lib.split(".")[0] in err.args[0]
+    ]
+    if not is_cuda_lib_err:
+        return False
+    for lib_folder, lib_name in cuda_libs.items():
+        _preload_cuda_dep(lib_folder, lib_name)
+    return True
+
+
 # See Note [Global dependencies]
 def _load_global_deps() -> None:
     if _running_with_deploy() or platform.system() == "Windows":
@@ -332,45 +370,14 @@ def _load_global_deps() -> None:
                 return
             # If all above-mentioned conditions are met, preload nvrtc and nvjitlink
             # Please note that order are important for CUDA-11.8 , as nvjitlink does not exist there
-            _preload_cuda_deps("cuda_nvrtc", "libnvrtc.so.*[0-9]")
-            _preload_cuda_deps("nvjitlink", "libnvJitLink.so.*[0-9]")
+            _preload_cuda_dep("cuda_nvrtc", "libnvrtc.so.*[0-9]")
+            _preload_cuda_dep("nvjitlink", "libnvJitLink.so.*[0-9]")
         except Exception:
             pass
 
     except OSError as err:
-        # Can only happen for wheel with cuda libs as PYPI deps
-        # As PyTorch is not purelib, but nvidia-*-cu12 is
-        from torch.version import cuda as cuda_version
-
-        cuda_libs: dict[str, str] = {
-            "cublas": "libcublas.so.*[0-9]",
-            "cudnn": "libcudnn.so.*[0-9]",
-            "cuda_nvrtc": "libnvrtc.so.*[0-9]",
-            "cuda_runtime": "libcudart.so.*[0-9]",
-            "cuda_cupti": "libcupti.so.*[0-9]",
-            "cufft": "libcufft.so.*[0-9]",
-            "curand": "libcurand.so.*[0-9]",
-            "nvjitlink": "libnvJitLink.so.*[0-9]",
-            "cusparse": "libcusparse.so.*[0-9]",
-            "cusparselt": "libcusparseLt.so.*[0-9]",
-            "cusolver": "libcusolver.so.*[0-9]",
-            "nccl": "libnccl.so.*[0-9]",
-        }
-        # cufiile is only available on cuda 12+
-        # TODO: Remove once CUDA 11.8 binaries are deprecated
-        if cuda_version is not None:
-            t_version = cuda_version.split(".")
-            t_major = int(t_version[0])  # type: ignore[operator]
-            if t_major >= 12:
-                cuda_libs["cufile"] = "libcufile.so.*[0-9]"
-
-        is_cuda_lib_err = [
-            lib for lib in cuda_libs.values() if lib.split(".")[0] in err.args[0]
-        ]
-        if not is_cuda_lib_err:
+        if not _preload_cuda_deps(err):
             raise err
-        for lib_folder, lib_name in cuda_libs.items():
-            _preload_cuda_deps(lib_folder, lib_name)
         ctypes.CDLL(global_deps_lib_path, mode=ctypes.RTLD_GLOBAL)
 
 
@@ -396,7 +403,13 @@ if (USE_RTLD_GLOBAL_WITH_LIBTORCH or os.getenv("TORCH_USE_RTLD_GLOBAL")) and (
     old_flags = sys.getdlopenflags()
     sys.setdlopenflags(os.RTLD_GLOBAL | os.RTLD_LAZY)
 
-    from torch._C import *  # noqa: F403
+    try:
+        from torch._C import *  # noqa: F403
+    except ImportError as err:
+        if not _preload_cuda_deps(err):
+            raise err
+
+        from torch._C import *  # noqa: F403
 
     sys.setdlopenflags(old_flags)
     del old_flags
@@ -413,7 +426,13 @@ else:
     # See Note [Global dependencies]
     if USE_GLOBAL_DEPS:
         _load_global_deps()
-    from torch._C import *  # noqa: F403
+    try:
+        from torch._C import *  # noqa: F403
+    except ImportError as err:
+        if not _preload_cuda_deps(err):
+            raise err
+
+        from torch._C import *  # noqa: F403
 
 
 class SymInt:
@@ -993,7 +1012,13 @@ def sym_fresh_size(expr):
 # on what the problem might be.
 try:
     # _initExtension is chosen (arbitrarily) as a sentinel.
-    from torch._C import _initExtension
+    try:
+        from torch._C import _initExtension  # noqa: F403
+    except ImportError as err:
+        if not _preload_cuda_deps(err):
+            raise err
+
+        from torch._C import _initExtension  # noqa: F403
 except ImportError:
     import torch._C as _C_for_compiled_check
 
