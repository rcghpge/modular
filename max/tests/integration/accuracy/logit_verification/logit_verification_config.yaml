##===----------------------------------------------------------------------===##
# Copyright (c) 2026, Modular Inc. All rights reserved.
#
# Licensed under the Apache License v2.0 with LLVM Exceptions:
# https://llvm.org/LICENSE.txt
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
##===----------------------------------------------------------------------===##

agent_anchors:
  large_intel: &large_cpu
    pool: cpu
    arch: x86_64
    resource_class: "large"
  large_arm: &large_arm
    pool: arm
    arch: arm64
    resource_class: "large"
  h100_1x: &h100_1x
    queue: ephemeral
    pool: h100
    resource_class: "1x"
  h100_4x: &h200_4x
    queue: ephemeral
    pool: h200
    resource_class: "4x"
  b200_1x: &b200_1x
    queue: ephemeral
    pool: b200
    resource_class: "1x"
  b200_2x: &b200_2x
    queue: ephemeral
    pool: b200
    resource_class: "2x"
  b200_8x: &b200_8x
    queue: ephemeral
    pool: b200
    resource_class: "8x"
  mi355_1x: &mi355_1x
    queue: ephemeral
    pool: mi355
    resource_class: "1x"

logit_verification_pipelines:
  # Each pipeline is defined by a name and the following fields:
  # - `pre_submit_agents` is a list of agent configurations to run in pre-submit.
  #   If the list is empty, the pipeline will not be run in pre-submit.
  # - `pipeline` is the name of the huggingface model or pipeline to verify.
  meta-llama/Meta-Llama-3-8B-Instruct-float32:
    pre_submit_agents: [*large_cpu, *large_arm, *h100_1x, *b200_1x, *mi355_1x]
    pipeline: "meta-llama/Meta-Llama-3-8B-Instruct"

  meta-llama/Llama-3.1-8B-Instruct-float32:
    pre_submit_agents: [*large_cpu, *large_arm, *h100_1x, *b200_1x, *mi355_1x]
    pipeline: "meta-llama/Llama-3.1-8B-Instruct"

  sentence-transformers/all-mpnet-base-v2-float32:
    pre_submit_agents: [*large_cpu, *large_arm, *h100_1x, *b200_1x, *mi355_1x]
    pipeline: "sentence-transformers/all-mpnet-base-v2"

  unsloth/gpt-oss-20b-BF16:
    pre_submit_agents: [*h200_4x]
    pipeline: "unsloth/gpt-oss-20b-BF16"

  allenai/OLMo-1B-hf-float32:
    pre_submit_agents: [*large_cpu, *large_arm, *h100_1x, *b200_1x, *mi355_1x]
    pipeline: "allenai/OLMo-1B-hf"

  bartowski/Meta-Llama-3-8B-Instruct-GGUF-q4_k:
    pre_submit_agents: [*large_cpu, *large_arm]
    pipeline: "meta-llama/Meta-Llama-3-8B-Instruct"

  meta-llama/Meta-Llama-3-8B-Instruct-bfloat16:
    pre_submit_agents: [*h100_1x, *b200_1x, *mi355_1x]
    pipeline: "meta-llama/Meta-Llama-3-8B-Instruct"

  bartowski/Meta-Llama-3.1-8B-Instruct-GGUF-q4_k:
    pre_submit_agents: [*large_cpu, *large_arm]
    pipeline: "meta-llama/Llama-3.1-8B-Instruct"

  meta-llama/Llama-3.1-8B-Instruct-bfloat16:
    pre_submit_agents: [*h100_1x, *b200_1x, *mi355_1x]
    pipeline: "meta-llama/Llama-3.1-8B-Instruct"

  meta-llama/Llama-3.1-8B-Instruct-data-parallel-bfloat16:
    pre_submit_agents: [*b200_2x]
    pipeline: "meta-llama/Llama-3.1-8B-Instruct-data-parallel"

  RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8-float8-static:
    pre_submit_agents: [*h100_1x, *b200_1x]
    pipeline: "RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8-float8-static"

  RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8-dynamic-float8-dynamic:
    pre_submit_agents: [*h100_1x, *b200_1x]
    pipeline: "RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8-dynamic"

  nvidia/Llama-3.1-8B-Instruct-NVFP4:
    pre_submit_agents: [*b200_1x]
    pipeline: "nvidia/Llama-3.1-8B-Instruct-NVFP4"

  nvidia/Llama-3.1-405B-Instruct-NVFP4:
    pre_submit_agents: [*b200_2x]
    pipeline: "nvidia/Llama-3.1-405B-Instruct-NVFP4"

  meta-llama/Llama-3.2-1B-bfloat16:
    pre_submit_agents: [*h100_1x, *b200_1x]
    pipeline: "meta-llama/Llama-3.2-1B"

  meta-llama/Llama-3.3-70B-Instruct-bfloat16:
    pre_submit_agents: [*h200_4x, *b200_2x]
    pipeline: "meta-llama/Llama-3.3-70B-Instruct"

  meta-llama/Llama-4-Scout-17B-16E-Instruct-bfloat16:
    pre_submit_agents: [*h200_4x, *b200_2x]
    pipeline: "meta-llama/Llama-4-Scout-17B-16E-Instruct"

  mistralai/Mistral-Nemo-Instruct-2407-bfloat16:
    pre_submit_agents: [*h100_1x, *b200_1x, *mi355_1x]
    pipeline: "mistralai/Mistral-Nemo-Instruct-2407"

  mistralai/Mistral-Small-3.1-24B-Instruct-2503-bfloat16:
    pre_submit_agents: [*h100_1x, *b200_1x, *mi355_1x]
    pipeline: "mistralai/Mistral-Small-3.1-24B-Instruct-2503"

  OpenGVLab/InternVL3-1B-Instruct-bfloat16:
    pre_submit_agents: [*h100_1x, *b200_1x]
    pipeline: "OpenGVLab/InternVL3-1B-Instruct"

  OpenGVLab/InternVL3-8B-Instruct-bfloat16:
    pre_submit_agents: [*h200_4x, *b200_2x]
    pipeline: "OpenGVLab/InternVL3-8B-Instruct"

  OpenGVLab/InternVL3-14B-Instruct-bfloat16:
    pre_submit_agents: [*h200_4x, *b200_2x]
    pipeline: "OpenGVLab/InternVL3-14B-Instruct"

  OpenGVLab/InternVL3-38B-Instruct-bfloat16:
    pre_submit_agents: [*h200_4x, *b200_2x]
    pipeline: "OpenGVLab/InternVL3-38B-Instruct"

  OpenGVLab/InternVL3_5-8B-Instruct-bfloat16:
    pre_submit_agents: [*h200_4x, *b200_2x]
    pipeline: "OpenGVLab/InternVL3_5-8B-Instruct"

  mistral-community/pixtral-12b-bfloat16:
    pre_submit_agents: [*h100_1x, *b200_1x, *mi355_1x]
    pipeline: "mistral-community/pixtral-12b"

  Qwen/Qwen2.5-7B-Instruct-bfloat16:
    pre_submit_agents: [*h100_1x, *b200_1x]
    pipeline: "Qwen/Qwen2.5-7B-Instruct"

  Qwen/Qwen2.5VL-3B-Instruct-bfloat16:
    pre_submit_agents: [*h100_1x, *b200_1x, *mi355_1x]
    pipeline: "Qwen/Qwen2.5-VL-3B-Instruct"

  Qwen/Qwen2.5VL-7B-Instruct-bfloat16:
    pre_submit_agents: [*h200_4x, *b200_2x]
    pipeline: "Qwen/Qwen2.5-VL-7B-Instruct"

  Qwen/Qwen2.5VL-32B-Instruct-bfloat16:
    pre_submit_agents: [*h200_4x, *b200_2x]
    pipeline: "Qwen/Qwen2.5-VL-32B-Instruct"

  Qwen/Qwen3-VL-30B-A3B-Instruct:
    pre_submit_agents: [*h200_4x, *b200_2x]
    pipeline: "Qwen/Qwen3-VL-30B-A3B-Instruct"

  Qwen/Qwen3-VL-4B-Instruct-bfloat16:
    pre_submit_agents: [*h100_1x, *b200_1x, *mi355_1x]
    pipeline: "Qwen/Qwen3-VL-4B-Instruct"

  Qwen/Qwen3-VL-4B-Instruct-FP8:
    pre_submit_agents: [*h100_1x, *b200_1x, *mi355_1x]
    pipeline: "Qwen/Qwen3-VL-4B-Instruct-FP8"

  Qwen/Qwen3-8B-bfloat16:
    pre_submit_agents: [*h100_1x, *b200_1x]
    pipeline: "Qwen/Qwen3-8B"

  Qwen/Qwen3-30B-A3B-Instruct-2507-bfloat16:
    pre_submit_agents: [*b200_1x]
    pipeline: "Qwen/Qwen3-30B-A3B-Instruct-2507"

  Qwen/Qwen3-Embedding-0.6B-bfloat16:
    pre_submit_agents: [*h100_1x, *b200_1x, *mi355_1x]
    pipeline: "Qwen/Qwen3-Embedding-0.6B"

  allenai/olmOCR-2-7B-1025-FP8:
    pre_submit_agents: [*h100_1x, *b200_1x]
    pipeline: "allenai/olmOCR-2-7B-1025-FP8"

  allenai/OLMo-2-1124-7B-float32:
    pre_submit_agents: [*large_cpu, *large_arm, *h100_1x, *b200_1x, *mi355_1x]
    pipeline: "allenai/OLMo-2-1124-7B"

  allenai/Olmo-3-7B-Instruct-bfloat16:
    pre_submit_agents: [*h100_1x, *b200_1x, *mi355_1x]
    pipeline: "allenai/Olmo-3-7B-Instruct"

  HuggingFaceM4/Idefics3-8B-Llama3:
    pre_submit_agents: [*h100_1x, *b200_1x]
    pipeline: "HuggingFaceM4/Idefics3-8B-Llama3"

  LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct-float32:
    pre_submit_agents: [*large_cpu, *large_arm, *h100_1x, *b200_1x, *mi355_1x]
    pipeline: "LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct"

  microsoft/Phi-3.5-mini-instruct-bfloat16:
    pre_submit_agents: [*h100_1x, *b200_1x, *mi355_1x]
    pipeline: "microsoft/Phi-3.5-mini-instruct"

  microsoft/phi-4-bfloat16:
    pre_submit_agents: [*h100_1x, *b200_1x, *mi355_1x]
    pipeline: "microsoft/phi-4"

  hugging-quants/Meta-Llama-3.1-8B-Instruct-GPTQ-INT4-gptq:
    pre_submit_agents: [*h100_1x, *b200_1x]
    pipeline: "hugging-quants/Meta-Llama-3.1-8B-Instruct-GPTQ-INT4"

  hugging-quants/Meta-Llama-3.1-8B-Instruct-GPTQ-INT4-gptq-no-perm-idx:
    pre_submit_agents: [*h100_1x, *b200_1x]
    pipeline: "kaitchup/DeepSeek-R1-Distill-Llama-8B-AutoRound-GPTQ-4bit"

  deepseek-ai/DeepSeek-V2-Lite-Chat-bfloat16:
    pre_submit_agents: [*h100_1x, *b200_1x, *mi355_1x]
    pipeline: "deepseek-ai/DeepSeek-V2-Lite-Chat"

  kathywu95/deepseek-v3-small-random-bfloat16:
    pre_submit_agents: [*h100_1x]
    pipeline: "kathywu95/deepseek-v3-small-random"

  kathywu95/deepseek-v3-small-random-fp8:
    pre_submit_agents: [*b200_1x]
    pipeline: "kathywu95/deepseek-v3-small-random-fp8"

  deepseek-ai/DeepSeek-R1:
    pre_submit_agents: [*b200_8x]
    pipeline: "deepseek-ai/DeepSeek-R1"

  nvidia/DeepSeek-R1-0528-NVFP4-v2:
    pre_submit_agents: [*b200_8x]
    pipeline: "nvidia/DeepSeek-R1-0528-NVFP4-v2"

  google/gemma-3-1b-it-bfloat16:
    pre_submit_agents: [*h100_1x, *b200_1x, *mi355_1x]
    pipeline: "google/gemma-3-1b-it"

  google/gemma-3-12b-it-bfloat16:
    pre_submit_agents: [*h100_1x, *b200_1x, *mi355_1x]
    pipeline: "google/gemma-3-12b-it"

  google/gemma-3-27b-it-bfloat16:
    pre_submit_agents: [*h200_4x, *b200_2x]
    pipeline: "google/gemma-3-27b-it"

  RedHatAI/gemma-3-27b-it-FP8-dynamic:
    pre_submit_agents: [*h100_1x, *b200_1x]
    pipeline: "RedHatAI/gemma-3-27b-it-FP8-dynamic"

  RedHatAI/gemma-3-27b-it-FP8-dynamic-multi:
    pre_submit_agents: [*h200_4x, *b200_2x]
    pipeline: "RedHatAI/gemma-3-27b-it-FP8-dynamic"

  HKUSTAudio/Llasa-8B-bfloat16:
    pre_submit_agents: [*h100_1x, *b200_1x, *mi355_1x]
    pipeline: "HKUSTAudio/Llasa-8B"

  HuggingFaceTB/SmolLM2-360M-Instruct-LoRA-bfloat16:
    pre_submit_agents: [*h100_1x, *b200_1x]
    pipeline: "HuggingFaceTB/SmolLM2-360M-Instruct"

  RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8-dynamic-BF16-LoRA:
    pre_submit_agents: [*b200_1x]
    pipeline: "RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8-dynamic-BF16-LoRA"
