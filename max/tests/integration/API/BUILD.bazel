load("@pip_deps//:requirements.bzl", "requirement")
load("//bazel:api.bzl", "lit_tests")

filegroup(
    name = "pytest_inputs",
    srcs = [
        "Inputs/relu3x100x100.onnx",
        "Inputs/relu3x100x100.torchscript",
        "c/custom-ops-override.api",
        "c/mo-model.api",
    ],
    visibility = [":__subpackages__"],
)

filegroup(
    name = "inputs",
    srcs = glob(["**/*.mlir"]),
    visibility = [":__subpackages__"],
)

lit_tests(
    name = "test",
    size = "large",
    srcs = glob([
        "**/*.api",
        "**/*.mojo",
    ]),
    available_features = [
        "GENERATED_ONNX_TESTS",
        "GENERATED_TESTS",
        "mtorch",
        "numpy",
        "pytorch-generated-tests",
        "requests",
    ],
    custom_substitutions = {
        "%pytorch_generated_tests_dir": "../../../../PyTorch/test/utils",
        "%onnx_test_models_dir": "../../../../../onnx~/onnx/backend/test/data/node",
        "%libpython": "$(rlocationpath //:libpython)",
    },
    data = [
        ":inputs",
        "//:libpython",
        "//GenericML:DeviceDriver",
        "//GenericML:modular-framework-common",
        "//KGEN:CompilerRT",
        "//KGEN:CompilerRT.distributable",
        "//ModelServing:ServeRTCAPI",
        "//ModularFramework/tools/mof",
        # TODO(SDLC-918): remove when landed
        "//Kernels/mojo/Mogg:MOGG.lib.mlirbc",
        "//Kernels/mojo/Mogg:MOGGPrimitives.lib.mlirbc",
        "//PyTorch:modular-framework-torch-ext",
        "//PyTorch/test/utils:pytorch-generated-tests",
        "//PyTorch/tools/torch:mtorch",
        "//SDK/integration-test:inputs",
        "@llvm-project//compiler-rt:orc_rt",
        "@onnx//onnx/backend/test/data/node:test_abs",
    ],
    env = {
        "MODULAR_MAX_ENABLE_MODEL_IR_CACHE": "false",
    },
    gpu_only_srcs = [
        "c/gpu.api",
        "mojo/test_devicetensor_gpu.mojo",
    ],
    mojo_deps = [
        "//SDK/lib/API/mojo/max/max",
        "//open-source/mojo/stdlib/stdlib",
        "//Kernels/mojo/register",
    ],
    tags = [
        "gpu",
        "no-sandbox",  # These tests use openmp which validates only 1 shared library is loaded at the same time, the libraries in the sandbox appear different so running them in parallel fails otherwise.
    ],
    target_compatible_with = select({
        "//:asan": ["@platforms//:incompatible"],
        "//conditions:default": [],
    }),
    tools = [
        "//CUDASupport/tools/is-cuda-available",
        "//GenericML/tools/mt",
        "//KGEN/tools/mojo",
        "//SDK/tools/modular-api-executor",
    ],
    deps = [
        requirement("numpy"),
        requirement("requests"),
        requirement("torch"),
        requirement("torchvision"),
    ],
)
