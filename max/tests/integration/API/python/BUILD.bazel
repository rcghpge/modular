load("//bazel:api.bzl", "modular_py_test", "modular_run_binary_test", "requirement")

modular_py_test(
    name = "tests-pure",
    size = "large",
    srcs = [
        "conftest.py",
        "test_cli.py",
        "test_config_pure.py",
        "test_context.py",
        "test_cumsum.py",
        "test_dtype.py",
        "test_engine.py",
        "test_explicit_device.py",
        "test_graph_telemetry.py",
        "test_huggingface_utilities_pure.py",
        "test_load_weights.py",
        "test_memory_estimation.py",
        "test_registry.py",
        "test_telemetry.py",
    ],
    data = [
        "//PyTorch:TorchRuntimePlugins",
        "//PyTorch/tools/torch:mtorch",
        "//SDK/integration-test/API:inputs",
        "//SDK/integration-test/API:pytest_inputs",
        "//SDK/lib/API/python/tests/graph/testdata",
    ],
    env = {
        "MODULAR_PATH": ".",
        "GRAPH_TESTDATA": "SDK/lib/API/python/tests/graph/testdata",
    },
    tags = ["gpu"],
    deps = [
        "//SDK/integration-test/pipelines/python/test_common",
        "//SDK/lib/API/python/max",
        "//SDK/lib/API/python/max/entrypoints",
        # TODO(MAXPLAT-85): mypy doesn't inherit requirements
        requirement("click"),
        requirement("gguf"),
        requirement("hypothesis"),
        requirement("safetensors"),
        requirement("torch"),
        requirement("transformers"),
    ],
)

modular_py_test(
    name = "tests-hf",
    size = "large",
    srcs = [
        "conftest.py",
        "test_config.py",
        "test_huggingface_utilities.py",
        "test_sampling.py",
        "test_speculative_decoding.py",
        "test_tokenizer.py",
    ],
    data = [
        # TODO(MAXPLAT-86): Find a shared place for these tools
        "//PyTorch:TorchRuntimePlugins",
        "//PyTorch/tools/torch:mtorch",
        "//SDK/integration-test/API:inputs",
        "//SDK/integration-test/API:pytest_inputs",
    ],
    env = {"MODULAR_PATH": "."},
    env_inherit = ["HF_TOKEN"],
    gpu_constraints = ["//:has_gpu"],
    tags = [
        "AITLIB-293",
        "gpu",
        "manual",  # TODO(AITLIB-293)
        "no-sandbox",
        "requires-network",
    ],
    deps = [
        "//SDK/integration-test/pipelines/python/test_common",
        "//SDK/lib/API/python/max",
        "//SDK/lib/API/python/max/entrypoints",
        # TODO(MAXPLAT-85): mypy doesn't inherit requirements
        requirement("click"),
        requirement("gguf"),
        requirement("safetensors"),
        requirement("torch"),
        requirement("transformers"),
        requirement("xgrammar"),
    ],
)

modular_py_test(
    name = "multi-gpu-tests",
    size = "large",
    srcs = glob(["multi_gpu_tests/**/*.py"]),
    data = [
        "//ModularFramework/tools/max",
        "//PyTorch:ATenRT",
        "//PyTorch:TorchRuntimePlugins",
        "//PyTorch/tools/torch:mtorch",
        "//SDK/integration-test:test_user_op",
        "//SDK/integration-test/API:inputs",
        "//SDK/integration-test/API:pytest_inputs",
        "//SDK/lib/API/python/tests/graph/testdata",
    ],
    env = {
        "CUSTOM_OPS_PATH": "$(rootpath //SDK/integration-test:test_user_op)",
        "MODULAR_PATH": ".",
        "GRAPH_TESTDATA": "SDK/lib/API/python/tests/graph/testdata",
    },
    exec_properties = {
        # 2 here means *at least* 2 GPUs, in practice CI will have 4
        "resources:gpu-count": "2",
    },
    gpu_constraints = ["//:has_multi_gpu"],
    tags = ["multi-gpu"],
    deps = [
        "//SDK/lib/API/python/max/engine",
        "//SDK/lib/API/python/max/nn",
        requirement("numpy"),
    ],
)

modular_run_binary_test(
    name = "pipelines_multi_gpu_smoke_test",
    args = [
        "generate",
        "--model-path",
        "hf-internal-testing/tiny-random-LlamaForCausalLM",
        "--devices=gpu:0,1,2,3",
        "--max-batch-size=1",
        "--max-new-tokens=32",
        "--max-num-steps=1",
        "--max-length=512",
    ],
    binary = "//SDK/lib/API/python/max/entrypoints:pipelines",
    env = {
        "MODULAR_DISABLE_HF_NETWORK_ACCESS": "1",
    },
    exec_properties = {
        # 2 here means *at least* 2 GPUs, in practice CI will have 4
        "resources:gpu-count": "2",
    },
    gpu_constraints = ["//:has_multi_gpu"],
    tags = [
        "multi-gpu",
        "no-sandbox",
    ],
)
