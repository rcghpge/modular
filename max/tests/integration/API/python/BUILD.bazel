load("//bazel:api.bzl", "modular_py_test", "modular_run_binary_test", "requirement")

modular_py_test(
    name = "tests-pure",
    size = "large",
    srcs = [
        "conftest.py",
        "test_context.py",
        "test_dtype.py",
        "test_engine.py",
        "test_graph_telemetry.py",
        "test_telemetry.py",
    ],
    data = [
        # TODO(MAXPLAT-86): Find a shared place for these tools
        "//ONNX/tools/onnx:monnx",
        "//PyTorch:TorchRuntimePlugins",
        "//PyTorch/tools/torch:mtorch",
        "//SDK/integration-test/API:inputs",
        "//SDK/integration-test/API:pytest_inputs",
    ],
    env = {"MODULAR_PATH": "."},
    deps = [
        "//SDK/integration-test/API/python/test_common",
        "//SDK/lib/API/python/max",
        "//SDK/lib/API/python/max/entrypoints",
        # TODO(MAXPLAT-85): mypy doesn't inherit requirements
        requirement("click"),
        requirement("gguf"),
        requirement("hypothesis"),
        requirement("safetensors"),
        requirement("sentencepiece"),
        requirement("torch"),
        requirement("transformers"),
    ],
)

modular_py_test(
    name = "tests-hf",
    size = "large",
    srcs = [
        "conftest.py",
        "test_cli.py",
        "test_config.py",
        "test_huggingface_utilities.py",
        "test_tokenizer.py",
    ],
    data = [
        # TODO(MAXPLAT-86): Find a shared place for these tools
        "//ONNX/tools/onnx:monnx",
        "//PyTorch:TorchRuntimePlugins",
        "//PyTorch/tools/torch:mtorch",
        "//SDK/integration-test/API:inputs",
        "//SDK/integration-test/API:pytest_inputs",
    ],
    env = {"MODULAR_PATH": "."},
    env_inherit = ["HF_TOKEN"],
    tags = [
        "no-sandbox",
        "requires-network",
    ],
    deps = [
        "//SDK/integration-test/API/python/test_common",
        "//SDK/lib/API/python/max",
        "//SDK/lib/API/python/max/entrypoints",
        # TODO(MAXPLAT-85): mypy doesn't inherit requirements
        requirement("click"),
        requirement("gguf"),
        requirement("safetensors"),
        requirement("sentencepiece"),
        requirement("torch"),
        requirement("transformers"),
    ],
)

modular_py_test(
    name = "gpu-tests-pure",
    size = "large",
    srcs = [
        "gpu_tests/conftest.py",
        "gpu_tests/test_cumsum_gpu.py",
        "gpu_tests/test_engine.py",
        "gpu_tests/test_explicit_device.py",
        "gpu_tests/test_gpu_weight.py",
        "gpu_tests/test_load_weights_fp8.py",
    ],
    data = [
        "//ModularFramework/tools/mof",
        "//ONNX/tools/onnx:monnx",
        "//PyTorch:ATenRT",
        "//PyTorch:TorchRuntimePlugins",
        "//PyTorch/tools/torch:mtorch",
        "//SDK/integration-test:test_user_op",
        "//SDK/integration-test/API:inputs",
        "//SDK/integration-test/API:pytest_inputs",
        "//SDK/lib/API/python/tests/graph/testdata",
    ],
    env = {
        "CUSTOM_OPS_PATH": "$(rootpath //SDK/integration-test:test_user_op)",
        "MODULAR_PATH": ".",
        "GRAPH_TESTDATA": "SDK/lib/API/python/tests/graph/testdata",
    },
    gpu_constraints = ["//:has_gpu"],
    tags = [
        "gpu",
        "no-mypy",  # TODO: fix and remove
    ],
    deps = [
        "//SDK/integration-test/API/python/test_common",
        "//SDK/lib/API/python/max/engine",
        "//SDK/lib/API/python/max/entrypoints",
        requirement("click"),
        requirement("numpy"),
        requirement("safetensors"),
        requirement("torch"),
        requirement("xgrammar"),
        requirement("setuptools"),
    ],
)

modular_py_test(
    name = "gpu-tests-hf",
    size = "large",
    srcs = [
        "gpu_tests/conftest.py",
        "gpu_tests/test_cli.py",
        "gpu_tests/test_config.py",
        "gpu_tests/test_registry_gpu.py",
        "gpu_tests/test_sampling_gpu.py",
        "gpu_tests/test_tokenizer_gpu.py",
    ],
    data = [
        "//ModularFramework/tools/mof",
        "//ONNX/tools/onnx:monnx",
        "//PyTorch:ATenRT",
        "//PyTorch:TorchRuntimePlugins",
        "//PyTorch/tools/torch:mtorch",
    ],
    env = {"MODULAR_PATH": "."},
    gpu_constraints = ["//:has_gpu"],
    tags = [
        "gpu",
        "no-mypy",  # TODO: fix and remove
        "requires-network",
    ],
    deps = [
        "//SDK/integration-test/API/python/test_common",
        "//SDK/lib/API/python/max/engine",
        "//SDK/lib/API/python/max/entrypoints",
        requirement("click"),
        requirement("numpy"),
        requirement("safetensors"),
        requirement("torch"),
        requirement("xgrammar"),
        requirement("setuptools"),
    ],
)

modular_py_test(
    name = "multi-gpu-tests",
    size = "large",
    srcs = glob(["multi_gpu_tests/**/*.py"]),
    data = [
        "//ModularFramework/tools/mof",
        "//ONNX/tools/onnx:monnx",
        "//PyTorch:ATenRT",
        "//PyTorch:TorchRuntimePlugins",
        "//PyTorch/tools/torch:mtorch",
        "//SDK/integration-test:test_user_op",
        "//SDK/integration-test/API:inputs",
        "//SDK/integration-test/API:pytest_inputs",
        "//SDK/lib/API/python/tests/graph/testdata",
    ],
    env = {
        "CUSTOM_OPS_PATH": "$(rootpath //SDK/integration-test:test_user_op)",
        "MODULAR_PATH": ".",
        "GRAPH_TESTDATA": "SDK/lib/API/python/tests/graph/testdata",
    },
    exec_properties = {
        # 2 here means *at least* 2 GPUs, in practice CI will have 4
        "resources:gpu-count": "2",
    },
    gpu_constraints = ["//:has_multi_gpu"],
    tags = ["multi-gpu"],
    deps = [
        "//SDK/lib/API/python/max/engine",
        "//SDK/lib/API/python/max/nn",
        requirement("numpy"),
    ],
)

modular_run_binary_test(
    name = "pipelines_multi_gpu_smoke_test",
    args = [
        "generate",
        "--model-path",
        "modularai/Llama-3.1-8B-Instruct-GGUF",
        "--devices=gpu:0,1,2,3",
        "--max-batch-size=1",
        "--max-new-tokens=32",
        "--max-num-steps=1",
        "--max-length=512",
    ],
    binary = "//SDK/lib/API/python/max/entrypoints:pipelines",
    exec_properties = {
        # 2 here means *at least* 2 GPUs, in practice CI will have 4
        "resources:gpu-count": "2",
    },
    gpu_constraints = ["//:has_multi_gpu"],
    tags = [
        "multi-gpu",
        "no-sandbox",
        "requires-network",
    ],
)
