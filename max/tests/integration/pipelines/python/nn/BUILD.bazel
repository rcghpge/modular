# Test for shared layers.

load("//bazel:api.bzl", "modular_py_test", "requirement")

modular_py_test(
    name = "test_tokenizer",
    size = "small",
    srcs = glob(
        ["**/test_tokenizer.py"],
    ),
    data = [
        "//Kernels/tools/gpu-query",
        "//Support/tools/system-info",
    ],
    tags = [
        "manual",  # TODO(AITLIB-293)
        "no-sandbox",
        "requires-network",
    ],
    deps = [
        "//SDK/integration-test/API/python/graph:modular_graph_test",
        "//SDK/integration-test/pipelines/python/test_common",
        "//SDK/lib/API/python/max/engine",
        "//SDK/lib/API/python/max/nn",
        "//SDK/lib/API/python/max/pipelines",
        "//SDK/lib/API/python/max/pipelines/context",
        "//SDK/lib/API/python/max/pipelines/dataprocessing",
        "//SDK/lib/API/python/max/pipelines/kv_cache",
        "//SDK/lib/API/python/max/serve",
        requirement("torch"),
        requirement("transformers"),
        requirement("hypothesis"),
        requirement("sentencepiece"),
        requirement("gguf"),
        requirement("pytest-mock"),
        requirement("pytest-asyncio"),
    ],
)

modular_py_test(
    name = "tests",
    size = "large",
    srcs = glob(
        [
            "**/*.py",
        ],
        exclude = [
            "**/*_gpu.py",
            "**/*_distributed_gpu.py",
            "**/test_tokenizer.py",
        ],
    ),
    data = [
        "//GenericML:MGPRT",
        "//Kernels/tools/gpu-query",
        "//Support/tools/system-info",
    ],
    deps = [
        "//SDK/integration-test/API/python/graph:modular_graph_test",
        "//SDK/integration-test/pipelines/python/test_common",
        "//SDK/lib/API/python/max/engine",
        "//SDK/lib/API/python/max/nn",
        "//SDK/lib/API/python/max/nn/hooks",
        "//SDK/lib/API/python/max/pipelines",
        "//SDK/lib/API/python/max/pipelines/dataprocessing",
        "//SDK/lib/API/python/max/serve",
        requirement("torch"),
        requirement("transformers"),
        requirement("hypothesis"),
        requirement("sentencepiece"),
        requirement("gguf"),
        requirement("pytest-mock"),
        requirement("pytest-asyncio"),
    ],
)

modular_py_test(
    name = "tests_gpu",
    srcs = glob(
        [
            "**/*_gpu.py",
        ],
        exclude = [
            "**/*_distributed_gpu.py",
            "**/*_attention_gpu.py",
        ],
    ),
    data = [
        "//GenericML:MGPRT",
        "//Kernels/tools/gpu-query",
        "//Support/tools/system-info",
    ],
    gpu_constraints = ["//:has_gpu"],
    tags = [
        "gpu",
    ],
    deps = [
        "//SDK/integration-test/API/python/graph:modular_graph_test",
        "//SDK/integration-test/pipelines/python/test_common",
        "//SDK/lib/API/python/max/engine",
        "//SDK/lib/API/python/max/nn",
        "//SDK/lib/API/python/max/pipelines",
        "//SDK/lib/API/python/max/pipelines/dataprocessing",
        "//SDK/lib/API/python/max/serve",
        requirement("torch"),
        requirement("transformers"),
        requirement("hypothesis"),
        requirement("sentencepiece"),
        requirement("gguf"),
        requirement("pytest-asyncio"),
    ],
)

modular_py_test(
    name = "tests_distributed_gpu",
    size = "enormous",
    srcs = glob(["**/*_distributed_gpu.py"]),
    data = [
        "//GenericML:MGPRT",
        "//Kernels/tools/gpu-query",
        "//Support/tools/system-info",
    ],
    exec_properties = {
        # 2 here means *at least* 2 GPUs, in practice CI will have 4
        "resources:gpu-count": "2",
    },
    gpu_constraints = ["//:has_multi_gpu"],
    tags = [
        "multi-gpu",
        "no-mypy",  # TODO: Fix and remove
    ],
    deps = [
        "//SDK/integration-test/API/python/graph:modular_graph_test",
        "//SDK/integration-test/pipelines/python/test_common",
        "//SDK/lib/API/python/max/engine",
        "//SDK/lib/API/python/max/nn",
        "//SDK/lib/API/python/max/pipelines",
        "//SDK/lib/API/python/max/pipelines/dataprocessing",
        "//SDK/lib/API/python/max/serve",
        requirement("torch"),
        requirement("transformers"),
        requirement("hypothesis"),
        requirement("sentencepiece"),
        requirement("gguf"),
        requirement("pytest-asyncio"),
    ],
)

modular_py_test(
    name = "tests_attention_gpu",
    srcs = glob(
        [
            "**/*_attention_gpu.py",
        ],
    ),
    data = [
        "//GenericML:MGPRT",
        "//Kernels/tools/gpu-query",
        "//Support/tools/system-info",
        "@flash_attn",
    ],
    env = {
        "BAZEL": "true",
    },
    gpu_constraints = ["//:has_gpu"],
    tags = [
        "gpu",
    ],
    deps = [
        "//SDK/integration-test/API/python/graph:modular_graph_test",
        "//SDK/integration-test/pipelines/python/test_common",
        "//SDK/lib/API/python/max/engine",
        "//SDK/lib/API/python/max/nn",
        "//SDK/lib/API/python/max/pipelines",
        "//SDK/lib/API/python/max/pipelines/dataprocessing",
        "//SDK/lib/API/python/max/serve",
        requirement("torch"),
        requirement("transformers"),
        requirement("hypothesis"),
        requirement("sentencepiece"),
        requirement("gguf"),
        requirement("nvitop"),
        requirement("pytest-asyncio"),
    ],
)
