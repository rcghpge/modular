load("@pip_deps//:requirements.bzl", "requirement")
load("//bazel:api.bzl", "modular_py_test")

py_binary(
    name = "evaluate_llama",
    srcs = ["evaluate_llama.py"],
    data = [
        "//KGEN:CompilerRT",
        "//Kernels/tools/cuda-query",
        "//Support/tools/system-info",
        "@llvm-project//compiler-rt:orc_rt",
    ],
    env = {
        "MODULAR_MOJO_MAX_ORCRT_PATH": "$(location @llvm-project//compiler-rt:orc_rt)",
        "MODULAR_MOJO_MAX_COMPILERRT_PATH": "$(location //KGEN:CompilerRT)",
        "MODULAR_CUDA_QUERY_PATH": "$(location //Kernels/tools/cuda-query)",
        "MODULAR_SYSTEM_INFO_PATH": "$(location //Support/tools/system-info)",
        "PIPELINES_TESTDATA": "SDK/integration-test/pipelines/python/testdata",
    },
    imports = ["."],
    visibility = ["//visibility:public"],
    deps = [
        "//SDK/public/max-repo/pipelines/python/llama3",
        requirement("click"),
        requirement("py-cpuinfo"),
    ],
)

py_binary(
    name = "evaluate_batch_scenarios",
    srcs = ["evaluate_batch_scenarios.py"],
    data = [
        "//KGEN:CompilerRT",
        "//Kernels/tools/cuda-query",
        "//Support/tools/system-info",
        "@llvm-project//compiler-rt:orc_rt",
    ],
    env = {
        "MODULAR_MOJO_MAX_ORCRT_PATH": "$(location @llvm-project//compiler-rt:orc_rt)",
        "MODULAR_MOJO_MAX_COMPILERRT_PATH": "$(location //KGEN:CompilerRT)",
        "MODULAR_CUDA_QUERY_PATH": "$(location //Kernels/tools/cuda-query)",
        "MODULAR_SYSTEM_INFO_PATH": "$(location //Support/tools/system-info)",
        "PIPELINES_TESTDATA": "SDK/integration-test/pipelines/python/testdata",
    },
    imports = ["."],
    visibility = ["//visibility:public"],
    deps = [
        "//SDK/lib/API/python/max/pipelines",
        "//SDK/public/max-repo/pipelines/python/llama3",
        "//SDK/public/max-repo/pipelines/python/utils",
        requirement("click"),
    ],
)

modular_py_test(
    name = "tests",
    size = "large",
    srcs = glob(
        ["**/test_*.py"],
        exclude = [
            "serve/**/*",
            "**/*_gpu.py",
        ],
    ) + ["conftest.py"],
    data = [
        "//KGEN:CompilerRT",
        "//ModularFramework/tools/mof",
        "//SDK/integration-test/pipelines/python/testdata",
        "//Support/tools/system-info",
        "@llvm-project//compiler-rt:orc_rt",
        "@test_llama_golden",
    ],
    env = {
        "BAZEL": "true",
        "MODULAR_PATH": ".",
        "PIPELINES_TESTDATA": "SDK/integration-test/pipelines/python/testdata",
        "MODULAR_SYSTEM_INFO_PATH": "$(location //Support/tools/system-info)",
    },
    requires_gpu = False,
    tags = ["requires-network"],
    tags = ["manual"],
    target_compatible_with = select({
        # TODO: Sanitizer libs aren't available when python loads pybind shared libs
        "//:asan": ["@platforms//:incompatible"],
        "//:tsan": ["@platforms//:incompatible"],
        "//conditions:default": [],
    }),
    deps = [
        ":evaluate_llama",
        "//SDK/lib/API/python:max_engine",
        "//SDK/lib/API/python/max/serve",
        "//SDK/public/max-repo/pipelines/python/llama3",
        "//SDK/public/max-repo/pipelines/python/nn",
        "//SDK/public/max-repo/pipelines/python/utils",
        "//Support/python:support",
        requirement("hypothesis"),
        requirement("transformers"),
        requirement("pytest-asyncio"),
        requirement("pytest-mock"),
    ],
)

modular_py_test(
    name = "tests_gpu",
    size = "enormous",
    srcs = glob(
        ["test_*_gpu.py"],
        exclude = ["serve/**/*"],
    ) + [
        "conftest.py",
    ],
    data = [
        "//KGEN:CompilerRT",
        "//Kernels/tools/cuda-query",
        "//ModularFramework/tools/mof",
        "//SDK/integration-test/pipelines/python/testdata",
        "//Support/tools/system-info",
        "@llvm-project//compiler-rt:orc_rt",
        "@test_llama_golden",
    ],
    env = {
        "BAZEL": "true",
        "MODULAR_CUDA_QUERY_PATH": "$(location //Kernels/tools/cuda-query)",
        "MODULAR_SYSTEM_INFO_PATH": "$(location //Support/tools/system-info)",
        "MODULAR_PATH": ".",
        "PIPELINES_TESTDATA": "SDK/integration-test/pipelines/python/testdata",
    },
    requires_gpu = True,
    tags = ["manual"],
    tags = [
        "gpu",
        "requires-network",
    ],
    target_compatible_with = select({
        # TODO: Sanitizer libs aren't available when python loads pybind shared libs
        "//:asan": ["@platforms//:incompatible"],
        "//:tsan": ["@platforms//:incompatible"],
        "//conditions:default": [],
    }),
    deps = [
        ":evaluate_llama",
        "//SDK/lib/API/python:max_engine",
        "//SDK/public/max-repo/pipelines/python/llama3",
        "//SDK/public/max-repo/pipelines/python/utils",
        "//Support/python:support",
        requirement("hypothesis"),
        requirement("transformers"),
        requirement("py-cpuinfo"),
    ],
)

# - - - - -
# Serve
# - - - - -

py_library(
    name = "params",
    testonly = True,
    srcs = ["serve/params.py"],
)

modular_py_test(
    name = "tests_serve_cpu",
    size = "large",
    srcs = [
        "conftest.py",
        "serve/conftest.py",
        "serve/test_tiny_llama_serving_cpu.py",
    ],
    data = [
        "//KGEN:CompilerRT",
        "//SDK/integration-test/pipelines/python/testdata",
        "@llvm-project//compiler-rt:orc_rt",
    ],
    env = {
        "BAZEL": "true",
        "MODULAR_PATH": ".",
        "PIPELINES_TESTDATA": "SDK/integration-test/pipelines/python/testdata",
    },
    requires_gpu = False,
    tags = ["manual"],
    tags = ["requires-network"],
    deps = [
        ":params",
        "//SDK/lib/API/python/max/serve",
        "//SDK/public/max-repo/pipelines/python/llama3",
    ],
)

modular_py_test(
    name = "tests_serve_gpu",
    size = "enormous",
    srcs = [
        "conftest.py",
        "serve/conftest.py",
        "serve/test_tiny_llama_serving_gpu.py",
    ],
    data = [
        "//KGEN:CompilerRT",
        "//SDK/integration-test/pipelines/python/testdata",
        "@llvm-project//compiler-rt:orc_rt",
    ],
    env = {
        "BAZEL": "true",
        "MODULAR_PATH": ".",
        "PIPELINES_TESTDATA": "SDK/integration-test/pipelines/python/testdata",
    },
    requires_gpu = True,
    tags = ["manual"],
    tags = [
        "gpu",
        "requires-network",
    ],
    deps = [
        ":params",
        "//SDK/lib/API/python:max_engine",
        "//SDK/lib/API/python/max/serve",
        "//SDK/public/max-repo/pipelines/python/llama3",
    ],
)
